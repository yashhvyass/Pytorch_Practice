# -*- coding: utf-8 -*-
"""FuelEfficiency_Regression_Pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/174lpd-TlQpq2mzvNrXg1FotRAe6EOUoQ

# Code
"""

import pandas as pd
import torch
import torch.nn as nn
import numpy as np
url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'

column_names = ['MPG', 'Cylinders', 'Diplacement', 'Horsepower', 'Weight', 'Acceleration', 'Model Year', 'Origin']

df = pd.read_csv(url, names=column_names, sep="\s+", index_col=False, na_values='?')

df.head()

print(df.isna().sum())
df = df.dropna()

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df_train, df_test = train_test_split(df, train_size=0.8, random_state=1)

train_stats = df_train.describe().transpose()
train_stats

df.info()

numeric_column_names = ['Cylinders', 'Diplacement', 'Horsepower', 'Weight', 'Acceleration']

sc = StandardScaler()
df_train[numeric_column_names] = sc.fit_transform(df_train[numeric_column_names])
df_test[numeric_column_names] = sc.transform(df_test[numeric_column_names])

df_train.tail()

# Put Model Year information into buckets
boundaries = torch.tensor([73, 76, 79])

v = torch.tensor(df_train['Model Year'].values)
df_train['ModelYear_Bucketed'] = torch.bucketize(v, boundaries, right=True)

v = torch.tensor(df_test['Model Year'].values)
df_test['ModelYear_Bucketed'] = torch.bucketize(v, boundaries, right=True)

numeric_column_names.append('ModelYear_Bucketed')

from torch.nn.functional import one_hot
total_origin = len(set(df_train['Origin']))

origin_encoded = one_hot(torch.from_numpy(df_train['Origin'].values) % total_origin)
x_train_numeric = torch.tensor(df_train[numeric_column_names].values)

x_train = torch.cat([x_train_numeric, origin_encoded], 1).float()

origin_encoded = one_hot(torch.from_numpy(df_test['Origin'].values)  % total_origin)
x_test_numeric = torch.tensor(df_test[numeric_column_names].values)

x_test = torch.cat([x_test_numeric, origin_encoded], 1).float()

y_train = torch.tensor(df_train['MPG'].values).float()
y_test = torch.tensor(df_test['MPG'].values).float()

# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)
# y_train = y_train.view(-1, 1)
# y_test = y_test.view(-1, 1)

# print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)

# Make a custom dataset or if second attribute is y/target then we can use TensorDataset directly.
from torch.utils.data import TensorDataset, DataLoader
train_ds = TensorDataset(x_train, y_train)
batch_size=8
torch.manual_seed(42)
train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)

hidden_units = [8, 4]
input_size=x_train.shape[1]
all_layers=[]
for hidden_unit in hidden_units:
  layer = nn.Linear(input_size, hidden_unit)
  all_layers.append(layer)
  all_layers.append(nn.ReLU())
  input_size=hidden_unit

all_layers.append(nn.Linear(hidden_units[-1], 1))

model = nn.Sequential(*all_layers)

model

loss_fn = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)

torch.manual_seed(1)
num_epochs=200
log_epochs=20

# Training Loop
for epoch in range(num_epochs):
  loss_hist = 0
  for x_batch, y_batch in train_dl:
    pred = model(x_batch)[:, 0] ## predictions for specific columns or all.
    loss = loss_fn(pred, y_batch)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()

    loss_hist += loss.item()

  if epoch % log_epochs==0:
    print(f'Epoch: {epoch}, Loss: {loss_hist/len(train_dl):.4f}')

with torch.no_grad():
  pred = model(x_test.float())[:, 0]
  loss = loss_fn(pred, y_test)
  print(f'Test MSE: {loss.item(): .4f}')
  print(f'Test MAE: {nn.L1Loss()(pred, y_test).item(): .4f}')

"""# Possible Error ->
You might face a situation where you get loss values as nan. This might be because of nan values present in the data.
"""

